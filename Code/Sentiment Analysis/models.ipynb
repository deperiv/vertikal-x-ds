{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
      "     ---------------------------------------- 5.5/5.5 MB 10.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp310-cp310-win_amd64.whl (3.3 MB)\n",
      "     ---------------------------------------- 3.3/3.3 MB 11.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from transformers) (1.23.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from transformers) (2022.10.31)\n",
      "Collecting huggingface-hub<1.0,>=0.10.0\n",
      "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
      "     -------------------------------------- 163.5/163.5 kB 9.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Collecting pyyaml>=5.1\n",
      "  Using cached PyYAML-6.0-cp310-cp310-win_amd64.whl (151 kB)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.8.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from requests->transformers) (1.26.12)\n",
      "Installing collected packages: tokenizers, pyyaml, filelock, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.8.0 huggingface-hub-0.10.1 pyyaml-6.0 tokenizers-0.13.2 transformers-4.24.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pysentimiento in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (0.5.2)\n",
      "Requirement already satisfied: emoji<2.0.0,>=1.6.1 in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from pysentimiento) (1.7.0)\n",
      "Requirement already satisfied: transformers>=4.13.0 in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from pysentimiento) (4.24.0)\n",
      "Requirement already satisfied: datasets>=1.13.3 in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from pysentimiento) (2.6.1)\n",
      "Requirement already satisfied: torch in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from pysentimiento) (1.13.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from datasets>=1.13.3->pysentimiento) (6.0)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from datasets>=1.13.3->pysentimiento) (0.18.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from datasets>=1.13.3->pysentimiento) (10.0.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from datasets>=1.13.3->pysentimiento) (3.8.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from datasets>=1.13.3->pysentimiento) (2.28.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from datasets>=1.13.3->pysentimiento) (2022.10.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from datasets>=1.13.3->pysentimiento) (4.64.1)\n",
      "Requirement already satisfied: dill<0.3.6 in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from datasets>=1.13.3->pysentimiento) (0.3.5.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from datasets>=1.13.3->pysentimiento) (1.23.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from datasets>=1.13.3->pysentimiento) (0.10.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from datasets>=1.13.3->pysentimiento) (21.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from datasets>=1.13.3->pysentimiento) (3.1.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from datasets>=1.13.3->pysentimiento) (1.5.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from datasets>=1.13.3->pysentimiento) (0.70.13)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from transformers>=4.13.0->pysentimiento) (0.13.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from transformers>=4.13.0->pysentimiento) (3.8.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from transformers>=4.13.0->pysentimiento) (2022.10.31)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from torch->pysentimiento) (4.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from aiohttp->datasets>=1.13.3->pysentimiento) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from aiohttp->datasets>=1.13.3->pysentimiento) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from aiohttp->datasets>=1.13.3->pysentimiento) (1.8.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from aiohttp->datasets>=1.13.3->pysentimiento) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from aiohttp->datasets>=1.13.3->pysentimiento) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from aiohttp->datasets>=1.13.3->pysentimiento) (2.1.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from aiohttp->datasets>=1.13.3->pysentimiento) (4.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from packaging->datasets>=1.13.3->pysentimiento) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from requests>=2.19.0->datasets>=1.13.3->pysentimiento) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from requests>=2.19.0->datasets>=1.13.3->pysentimiento) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from requests>=2.19.0->datasets>=1.13.3->pysentimiento) (1.26.12)\n",
      "Requirement already satisfied: colorama in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from tqdm>=4.62.1->datasets>=1.13.3->pysentimiento) (0.4.6)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from pandas->datasets>=1.13.3->pysentimiento) (2022.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from pandas->datasets>=1.13.3->pysentimiento) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\daniel\\desktop\\itsense\\vertikal\\vertikal\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets>=1.13.3->pysentimiento) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pysentimiento\n",
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DANIEL\\Desktop\\ITSENSE\\Vertikal\\vertikal\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading: 100%|██████████| 687/687 [00:00<00:00, 343kB/s]\n",
      "Downloading: 100%|██████████| 1.43G/1.43G [02:13<00:00, 10.7MB/s]\n",
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at siebert/sentiment-roberta-large-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "Downloading: 100%|██████████| 256/256 [00:00<00:00, 85.4kB/s]\n",
      "Downloading: 100%|██████████| 798k/798k [00:00<00:00, 1.59MB/s]\n",
      "Downloading: 100%|██████████| 456k/456k [00:00<00:00, 1.10MB/s]\n",
      "Downloading: 100%|██████████| 150/150 [00:00<00:00, 25.0kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9988656044006348}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "sentiment_analysis = pipeline(\"sentiment-analysis\",model=\"siebert/sentiment-roberta-large-english\")\n",
    "print(sentiment_analysis(\"I love this!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'NEGATIVE', 'score': 0.9828449487686157}]\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_analysis(\"Neither of us deserve that amazing oportunity\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DANIEL\\Desktop\\ITSENSE\\Vertikal\\vertikal\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading: 100%|██████████| 925/925 [00:00<00:00, 305kB/s]\n",
      "Downloading: 100%|██████████| 435M/435M [00:37<00:00, 11.5MB/s] \n",
      "Downloading: 100%|██████████| 334/334 [00:00<00:00, 37.2kB/s]\n",
      "Downloading: 100%|██████████| 858k/858k [00:00<00:00, 1.51MB/s]\n",
      "Downloading: 100%|██████████| 150/150 [00:00<00:00, 25.0kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(output=POS, probas={POS: 0.994, NEG: 0.003, NEU: 0.003})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pysentimiento import create_analyzer\n",
    "analyzer = create_analyzer(task=\"sentiment\", lang=\"es\")\n",
    "analyzer.predict(\"Qué gran jugador es Messi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(output=POS, probas={POS: 0.994, NEG: 0.003, NEU: 0.003})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.predict(\"Qué gran jugador es Messi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(output=NEG, probas={NEG: 0.999, POS: 0.001, NEU: 0.001})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.predict(\"Qué mal jugador es Messi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 502/502 [00:00<00:00, 167kB/s]\n",
      "Downloading: 100%|██████████| 5.07M/5.07M [00:00<00:00, 6.71MB/s]\n",
      "Downloading: 100%|██████████| 9.08M/9.08M [00:03<00:00, 2.66MB/s]\n",
      "Downloading: 100%|██████████| 239/239 [00:00<00:00, 18.4kB/s]\n",
      "loading file sentencepiece.bpe.model from cache at C:\\Users\\DANIEL/.cache\\huggingface\\hub\\models--papluca--xlm-roberta-base-language-detection\\snapshots\\a5d0aa75d23efee145d767a8eb0fbe22082a9c53\\sentencepiece.bpe.model\n",
      "loading file tokenizer.json from cache at C:\\Users\\DANIEL/.cache\\huggingface\\hub\\models--papluca--xlm-roberta-base-language-detection\\snapshots\\a5d0aa75d23efee145d767a8eb0fbe22082a9c53\\tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at C:\\Users\\DANIEL/.cache\\huggingface\\hub\\models--papluca--xlm-roberta-base-language-detection\\snapshots\\a5d0aa75d23efee145d767a8eb0fbe22082a9c53\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\DANIEL/.cache\\huggingface\\hub\\models--papluca--xlm-roberta-base-language-detection\\snapshots\\a5d0aa75d23efee145d767a8eb0fbe22082a9c53\\tokenizer_config.json\n",
      "Downloading: 100%|██████████| 1.42k/1.42k [00:00<00:00, 478kB/s]\n",
      "loading configuration file config.json from cache at C:\\Users\\DANIEL/.cache\\huggingface\\hub\\models--papluca--xlm-roberta-base-language-detection\\snapshots\\a5d0aa75d23efee145d767a8eb0fbe22082a9c53\\config.json\n",
      "Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"papluca/xlm-roberta-base-language-detection\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"ja\",\n",
      "    \"1\": \"nl\",\n",
      "    \"2\": \"ar\",\n",
      "    \"3\": \"pl\",\n",
      "    \"4\": \"de\",\n",
      "    \"5\": \"it\",\n",
      "    \"6\": \"pt\",\n",
      "    \"7\": \"tr\",\n",
      "    \"8\": \"es\",\n",
      "    \"9\": \"hi\",\n",
      "    \"10\": \"el\",\n",
      "    \"11\": \"ur\",\n",
      "    \"12\": \"bg\",\n",
      "    \"13\": \"en\",\n",
      "    \"14\": \"fr\",\n",
      "    \"15\": \"zh\",\n",
      "    \"16\": \"ru\",\n",
      "    \"17\": \"th\",\n",
      "    \"18\": \"sw\",\n",
      "    \"19\": \"vi\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"ar\": 2,\n",
      "    \"bg\": 12,\n",
      "    \"de\": 4,\n",
      "    \"el\": 10,\n",
      "    \"en\": 13,\n",
      "    \"es\": 8,\n",
      "    \"fr\": 14,\n",
      "    \"hi\": 9,\n",
      "    \"it\": 5,\n",
      "    \"ja\": 0,\n",
      "    \"nl\": 1,\n",
      "    \"pl\": 3,\n",
      "    \"pt\": 6,\n",
      "    \"ru\": 16,\n",
      "    \"sw\": 18,\n",
      "    \"th\": 17,\n",
      "    \"tr\": 7,\n",
      "    \"ur\": 11,\n",
      "    \"vi\": 19,\n",
      "    \"zh\": 15\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "Downloading: 100%|██████████| 1.11G/1.11G [01:36<00:00, 11.5MB/s]\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\DANIEL/.cache\\huggingface\\hub\\models--papluca--xlm-roberta-base-language-detection\\snapshots\\a5d0aa75d23efee145d767a8eb0fbe22082a9c53\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing XLMRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of XLMRobertaForSequenceClassification were initialized from the model checkpoint at papluca/xlm-roberta-base-language-detection.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use XLMRobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"papluca/xlm-roberta-base-language-detection\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"papluca/xlm-roberta-base-language-detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "predicted_class_id = logits.argmax().item()\n",
    "model.config.id2label[predicted_class_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'es'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\"Hola, mi perro es lindo\", return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "predicted_class_id = logits.argmax().item()\n",
    "model.config.id2label[predicted_class_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'es'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\"Qué mal juagdor es Messi\", return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "predicted_class_id = logits.argmax().item()\n",
    "model.config.id2label[predicted_class_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁', 'Qué', '▁mal', '▁jugador', '▁es', '▁Messi']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimate_tokens(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_auto_class',\n",
       " '_backward_compatibility_gradient_checkpointing',\n",
       " '_backward_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_can_retrieve_inputs_from_name',\n",
       " '_convert_head_mask_to_5d',\n",
       " '_create_repo',\n",
       " '_expand_inputs_for_generation',\n",
       " '_forward_hooks',\n",
       " '_forward_pre_hooks',\n",
       " '_from_config',\n",
       " '_get_backward_hooks',\n",
       " '_get_decoder_start_token_id',\n",
       " '_get_files_timestamps',\n",
       " '_get_logits_processor',\n",
       " '_get_logits_warper',\n",
       " '_get_name',\n",
       " '_get_resized_embeddings',\n",
       " '_get_resized_lm_head',\n",
       " '_get_stopping_criteria',\n",
       " '_hook_rss_memory_post_forward',\n",
       " '_hook_rss_memory_pre_forward',\n",
       " '_init_weights',\n",
       " '_is_full_backward_hook',\n",
       " '_keys_to_ignore_on_load_missing',\n",
       " '_keys_to_ignore_on_load_unexpected',\n",
       " '_keys_to_ignore_on_save',\n",
       " '_load_from_state_dict',\n",
       " '_load_pretrained_model',\n",
       " '_load_pretrained_model_low_mem',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_merge_criteria_processor_list',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_no_split_modules',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_prepare_attention_mask_for_generation',\n",
       " '_prepare_decoder_input_ids_for_generation',\n",
       " '_prepare_encoder_decoder_kwargs_for_generation',\n",
       " '_prepare_input_ids_for_generation',\n",
       " '_prepare_model_inputs',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_reorder_cache',\n",
       " '_replicate_for_data_parallel',\n",
       " '_resize_token_embeddings',\n",
       " '_save_to_state_dict',\n",
       " '_set_default_torch_dtype',\n",
       " '_set_gradient_checkpointing',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_tie_encoder_decoder_weights',\n",
       " '_tie_or_clone_weights',\n",
       " '_update_model_kwargs_for_generation',\n",
       " '_upload_modified_files',\n",
       " '_validate_model_class',\n",
       " '_validate_model_kwargs',\n",
       " '_version',\n",
       " 'add_memory_hooks',\n",
       " 'add_module',\n",
       " 'adjust_logits_during_generation',\n",
       " 'apply',\n",
       " 'base_model',\n",
       " 'base_model_prefix',\n",
       " 'beam_sample',\n",
       " 'beam_search',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'children',\n",
       " 'classifier',\n",
       " 'compute_transition_beam_scores',\n",
       " 'config',\n",
       " 'config_class',\n",
       " 'constrained_beam_search',\n",
       " 'contrastive_search',\n",
       " 'cpu',\n",
       " 'create_extended_attention_mask_for_decoder',\n",
       " 'cuda',\n",
       " 'device',\n",
       " 'double',\n",
       " 'dtype',\n",
       " 'dummy_inputs',\n",
       " 'dump_patches',\n",
       " 'estimate_tokens',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'floating_point_ops',\n",
       " 'forward',\n",
       " 'framework',\n",
       " 'from_pretrained',\n",
       " 'generate',\n",
       " 'get_buffer',\n",
       " 'get_extended_attention_mask',\n",
       " 'get_extra_state',\n",
       " 'get_head_mask',\n",
       " 'get_input_embeddings',\n",
       " 'get_memory_footprint',\n",
       " 'get_output_embeddings',\n",
       " 'get_parameter',\n",
       " 'get_position_embeddings',\n",
       " 'get_submodule',\n",
       " 'gradient_checkpointing_disable',\n",
       " 'gradient_checkpointing_enable',\n",
       " 'greedy_search',\n",
       " 'group_beam_search',\n",
       " 'half',\n",
       " 'init_weights',\n",
       " 'invert_attention_mask',\n",
       " 'ipu',\n",
       " 'is_gradient_checkpointing',\n",
       " 'is_parallelizable',\n",
       " 'load_state_dict',\n",
       " 'main_input_name',\n",
       " 'modules',\n",
       " 'name_or_path',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'num_labels',\n",
       " 'num_parameters',\n",
       " 'parameters',\n",
       " 'post_init',\n",
       " 'prune_heads',\n",
       " 'push_to_hub',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_for_auto_class',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'requires_grad_',\n",
       " 'reset_memory_hooks_state',\n",
       " 'resize_position_embeddings',\n",
       " 'resize_token_embeddings',\n",
       " 'retrieve_modules_from_names',\n",
       " 'roberta',\n",
       " 'sample',\n",
       " 'save_pretrained',\n",
       " 'set_extra_state',\n",
       " 'set_input_embeddings',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'supports_gradient_checkpointing',\n",
       " 'tie_weights',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'update_keys_to_ignore',\n",
       " 'warnings_issued',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('vertikal': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "70258f4837e3f46022aa0137b5be3a4e9270dc89d52dc988758cb74f0ce7bbb8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
